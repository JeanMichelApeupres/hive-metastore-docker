<configuration>
  <property><name>javax.jdo.option.ConnectionURL</name><value>jdbc:postgresql://pg:5432/hive-metastore</value></property>
  <property><name>javax.jdo.option.ConnectionDriverName</name><value>org.postgresql.Driver</value></property>
  <property><name>javax.jdo.option.ConnectionUserName</name><value>hive-metastore</value></property>
  <property><name>javax.jdo.option.ConnectionPassword</name><value>azerty123</value></property>
  <property><name>datanucleus.autoCreateSchema</name><value>true</value></property>
  <property><name>hive.metastore.warehouse.dir</name>  <value>/opt/hive/warehouse</value></property>
  <!-- Uncomment this part for S3a support
    <property><name>hive.metastore.warehouse.dir</name>  <value>s3a://bucket</value></property>
    <property><name>fs.s3a.connection.ssl.enabled</name>   <value>false</value></property>
    <property><name>fs.s3a.endpoint</name>                 <value>https://path.to.s3.endpoint.fr</value></property>
    <property><name>fs.s3a.endpoint.region</name>          <value>s3_region</value></property>
    <property><name>fs.s3a.access.key</name>               <value>AK</value></property>
    <property><name>fs.s3a.secret.key</name>               <value>SK</value></property>
    <property><name>fs.s3a.path.style.access</name>        <value>true</value></property>
    <property><name>fs.s3a.impl</name>                     <value>org.apache.hadoop.fs.s3a.S3AFileSystem</value></property>
    <property><name>fs.s3a.aws.credentials.provider</name> <value>org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider</value></property>
    <property><name>spark.hadoop.fs.s3a.fast.upload</name> <value>true</value></property>
  -->
</configuration>